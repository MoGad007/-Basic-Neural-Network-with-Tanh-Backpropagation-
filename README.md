# -Basic-Neural-Network-with-Tanh-Backpropagation-
# Basic Neural Network with Tanh & Backpropagation

This is a simple neural network with one hidden layer, using the **tanh activation function** and **backpropagation** for learning. The code is implemented **without external libraries**, only using Python's built-in `math` and `random` modules.

## ðŸ”¹ How It Works
1. **Initialize weights** randomly between -0.5 and 0.5.
2. **Forward propagation** to compute the output.
3. **Calculate error** and adjust weights using **backpropagation**.
4. Repeat until the network reaches the target output.

